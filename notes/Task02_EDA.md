
- 载入各种数据科学以及可视化库:
数据科学库 pandas、numpy、scipy；
可视化库 matplotlib、seabon；
[seabon官网](http://seaborn.pydata.org/index.html)
其他；
- 载入数据：
载入训练集和测试集；
简略观察数据(head()+shape)；
- 数据总览:
通过describe()来熟悉数据的相关统计量
通过info()来熟悉数据类型
- 判断数据缺失和异常
查看每列的存在nan情况
异常值检测
- 了解预测值的分布
总体分布概况（无界约翰逊分布等）
查看skewness and kurtosis
查看预测值的具体频数
- 特征分为类别特征和数字特征，并对类别特征查看unique分布
- 数字特征分析
相关性分析
查看几个特征得 偏度和峰值
每个数字特征得分布可视化
数字特征相互之间的关系可视化
多变量互相回归关系可视化
- 类型特征分析
unique分布
类别特征箱形图可视化
类别特征的小提琴图可视化
类别特征的柱形图可视化类别
特征的每个类别频数可视化(count_plot)
- 用pandas_profiling生成数据报告

## 1、EDA目的
EDA: Exploratory Data Analysis - 探索性数据分析
- EDA作为数据挖掘中最为关键的一步，它的价值主要在于熟悉数据集，了解数据集，对数据集进行验证来确定所获得数据集可以用于接下来的机器学习或者深度学习使用。
- 当了解了数据集之后我们下一步就是要去了解变量间的相互关系以及变量与预测值之间的存在关系。
- 引导数据科学从业者进行数据处理以及特征工程的步骤,使数据集的结构和特征集让接下来的预测问题更加可靠。
- 我们如果参加的数据挖掘比赛多了，就应该对数据有足够强的敏感性，可以快速的判断下一步该如何做。

## 2、主要内容
### 2.1、载入各种数据科学以及可视化库:
- 数据科学库 pandas、numpy、scipy；
- 可视化库 matplotlib、seabon；
- 其他；  
数据缺失可视化工具missingno：  
[missingno官方文档](https://github.com/ResidentMario/missingno)  
[缺失值可视化处理--missingno](https://blog.csdn.net/Andy_shenzl/article/details/81633356)
- [ ] 找一些相关的学习资源

### 2.2、载入数据
1）载入数据集
一般常用pandas读取文件，可以读取csv,txt,excel文件。一般比赛中给的数据都是压缩的，比如在这次比赛中的数据就是压缩的csv数据，因此我们**可以直接用pd.read_csv()读取压缩文件**，而不必要先解压在读取。
```bash
Train_data = pd.read_csv(path+'used_car_train_20200313.zip', sep=' ')
```
2）简略观察数据集
- 使用head()或者tail()查看头部尾部数据。
要养成看数据集的head()以及shape的习惯，这会让你每一步更放心，导致接下里的连串的错误, 如果对自己的pandas等操作不放心，建议执行一步看一下，这样会有效的方便你进行理解函数并进行操作



### 2.3、数据总览:
- 使用describe()来熟悉数据的相关统计量，里面包含最大值、最小值、均值、方差等。  
describe种有每列的统计量，个数count、平均值mean、方差std、最小值min、中位数25% 50% 75% 、以及最大值 看这个信息主要是瞬间掌握数据的大概的范围以及每个值的异常值的判断，比如有的时候会发现999 9999 -1 等值这些其实都是nan的另外一种表达方式，有的时候需要注意下
- 使用info()查看数据类型。
### 2.4、判断数据缺失和异常
- 使用isnull()查看那些值缺失，然后通过sum()查看每一列或每一行的缺失值。  
可以对于缺失值进行可视化，方便观察数据缺失情况。主要的目的在于 nan存在的个数是否真的很大，如果很小一般选择填充，如果使用lgb等树模型可以直接空缺，让树自己去优化，但如果nan存在的过多、可以考虑删掉
这里使用了[missingno](https://github.com/ResidentMario/missingno)，详细可以点击链接查看官方文档查看。
- 使用info()查看数据类型。可以看一下那些数据是非数值类型的，然后后面进行转换。  
通过info来了解数据每列的type，有助于了解是否存在除了nan以外的特殊符号异常。
通常对异常值进行替换或者异常值太多的时候不用这个特征。
- 可以对数据严重倾斜的特征删除，不实用特征，比如说每个特征可能全为1，这样的换就没有多大的意义。
### 2.5、了解预测值的分布
- 1、 总体分布概况（无界约翰逊分布等）  
这里用了seaborn，Seaborn是基于matplotlib的Python可视化库。 它提供了一个高级界面来绘制有吸引力的统计图形。Seaborn其实是在matplotlib的基础上进行了更高级的API封装，从而使得作图更加容易，不需要经过大量的调整就能使你的图变得精致。  

- 2、 查看skewness and kurtosis
skew、kurt说明参考[数据的偏度和峰度——df.skew()、df.kurt()](https://www.cnblogs.com/wyy1480/p/10474046.html)
-  3、 查看预测值的具体频数
log变换 z之后的分布较均匀，可以进行log变换进行预测，这也是预测问题常用的trick
### 2.6、特征分为类别特征和数字特征，并对类别特征查看unique分布
查看特征是属于数字特征还是类型特征，这里手动筛选特征，因为类型特征大部分也是用数字表示的。
使用unique查看有每一个特征有多少个不同的数据。
### 2.7、数字特征分析
- 相关性分析：查看特征之间的相关性
- 查看几个特征的 偏度和峰值
- 每个数字特征得分布可视化  
这里使用了pd.melt()函数。参考[Pandas 与数据整理](http://shzhangji.com/cnblogs/2017/09/30/pandas-and-tidy-data/)  
也使用了seaborn.FacetGrid()绘制数据网格，参考[Seaborn(sns)官方文档学习笔记（第六章 绘制数据网格）](https://zhuanlan.zhihu.com/p/27816821)
- 数字特征相互之间的关系可视化  
此处是多变量之间的关系可视化，可视化更多学习可参考[Seaborn-05-Pairplot多变量图
](https://www.jianshu.com/p/6e18d21a4cad)
- 多变量互相回归关系可视化
- [ ] **再仔细看一下这里**
### 2.8、类型特征分析
- 查看类型特征的unique分布
- 类别特征箱形图可视化
- 类别特征的小提琴图可视化
- 类别特征的柱形图可视化
- 类别特征的每个类别频数可视化(count_plot)
### 2.9、用pandas_profiling生成数据报告
用pandas_profiling生成一个较为全面的可视化和数据报告(较为简单、方便) 最终打开html文件即可

## 3、经验总结
所给出的EDA步骤为广为普遍的步骤，在实际的不管是工程还是比赛过程中，这只是最开始的一步，也是最基本的一步。
接下来一般要结合模型的效果以及特征工程等来分析数据的实际建模情况，根据自己的一些理解，查阅文献，对实际问题做出判断和深入的理解。
最后不断进行EDA与数据处理和挖掘，来到达更好的数据结构和分布以及较为强势相关的特征  
数据探索在机器学习中我们一般称为EDA（Exploratory Data Analysis）：
> 是指对已有的数据（特别是调查或观察得来的原始数据）在尽量少的先验假定下进行探索，通过作图、制表、方程拟合、计算特征量等手段探索数据的结构和规律的一种数据分析方法。


数据探索有利于我们发现数据的一些特性，数据之间的关联性，对于后续的特征构建是很有帮助的。

1. 对于数据的初步分析（直接查看数据，或.sum(), .mean()，.descirbe()等统计函数）可以从：样本数量，训练集数量，是否有时间特征，是否是时许问题，特征所表示的含义（非匿名特征），特征类型（字符类似，int，float，time），特征的缺失情况（注意缺失的在数据中的表现形式，有些是空的有些是”NAN”符号等），特征的均值方差情况。

2. 分析记录某些特征值缺失占比30%以上样本的缺失处理，有助于后续的模型验证和调节，分析特征应该是填充（填充方式是什么，均值填充，0填充，众数填充等），还是舍去，还是先做样本分类用不同的特征模型去预测。

3. 对于异常值做专门的分析，分析特征异常的label是否为异常值（或者偏离均值较远或者事特殊符号）,异常值是否应该剔除，还是用正常值填充，是记录异常，还是机器本身异常等。

4. 对于Label做专门的分析，分析标签的分布情况等。

5. 进步分析可以通过对特征作图，特征和label联合做图（统计图，离散图），直观了解特征的分布情况，通过这一步也可以发现数据之中的一些异常值等，通过箱型图分析一些特征值的偏离情况，对于特征和特征联合作图，对于特征和label联合作图，分析其中的一些关联性。